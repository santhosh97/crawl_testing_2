name: GitHub Stars Crawler

on:
  push:
    branches: [ main ]  # Run on push to main branch
  workflow_dispatch:  # Allow manual triggering
  schedule:
    - cron: '0 17 * * *'  # Run daily at 5:00 PM UTC

jobs:
  docker-crawler-all-tokens:
    runs-on: "ubuntu-latest"
    
    # Set environment variables for all steps
    env:
      TOKEN: ${{ secrets.TOKEN }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Docker Build
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        run: |
          docker build -t github-stars-crawler .
          echo "Docker image built successfully"
          
      - name: Start PostgreSQL container
        run: |
          docker run -d \
            --name postgres \
            -e POSTGRES_USER=postgres \
            -e POSTGRES_PASSWORD=postgres \
            -e POSTGRES_DB=github_stars \
            -p 5432:5432 \
            postgres:14
          
          # Wait for PostgreSQL to be ready
          echo "Waiting for PostgreSQL to be ready..."
          timeout 30s bash -c 'until docker exec postgres pg_isready -U postgres; do sleep 1; done'
          echo "PostgreSQL is ready"
      
      - name: Initialize database
        run: |
          # Export TOKEN secret to environment variable
          export TOKEN="${{ secrets.TOKEN }}"
          
          # Use the separate init_database.py script
          docker run --rm \
            --network host \
            -e DB_HOST=localhost \
            -e DB_PORT=5432 \
            -e DB_USER=postgres \
            -e DB_PASSWORD=postgres \
            -e DB_NAME=github_stars \
            -e DATABASE_URL=postgresql://postgres:postgres@localhost:5432/github_stars \
            -e TOKEN \
            --entrypoint python \
            github-stars-crawler \
            init_database.py
          
          echo "Database initialized successfully"
      
      - name: Run Crawler All Tokens
        run: |
          # Export TOKEN secret to environment variable
          export TOKEN="${{ secrets.TOKEN }}"
          
          # Create directories for outputs
          mkdir -p exports logs/metrics
          
          docker run --rm \
            --network host \
            -e DB_HOST=localhost \
            -e DB_PORT=5432 \
            -e DB_USER=postgres \
            -e DB_PASSWORD=postgres \
            -e DB_NAME=github_stars \
            -e DATABASE_URL=postgresql://postgres:postgres@localhost:5432/github_stars \
            -e TOKEN \
            -v $(pwd)/exports:/app/exports \
            -v $(pwd)/logs:/app/logs \
            --entrypoint python \
            github-stars-crawler \
            crawl.py --repos 10000 --workers 16 --batch-size 10000 --clean-db
          
          echo "Crawler completed successfully"
      
      - name: Export database to CSV
        run: |
          # Export TOKEN secret to environment variable
          export TOKEN="${{ secrets.TOKEN }}"
          
          # Export the database using the Docker container
          docker run --rm \
            --network host \
            -e DB_HOST=localhost \
            -e DB_PORT=5432 \
            -e DB_USER=postgres \
            -e DB_PASSWORD=postgres \
            -e DB_NAME=github_stars \
            -e DATABASE_URL=postgresql://postgres:postgres@localhost:5432/github_stars \
            -e TOKEN \
            -v $(pwd)/exports:/app/exports \
            --entrypoint python \
            github-stars-crawler \
            export_to_csv.py --verbose
          
          # Check if export was successful
          if [ -f exports/github_stars_export.csv ]; then
            echo "Export completed successfully"
            echo "File info: $(ls -la exports/github_stars_export.csv)"
            echo "Number of rows: $(wc -l < exports/github_stars_export.csv)"
          else
            echo "Export file not found, creating minimal CSV"
            echo "id,github_id,full_name,error_message" > exports/github_stars_export.csv
            echo "0,0,export_failed,file_not_found" >> exports/github_stars_export.csv
          fi
      
      - name: Upload CSV export as artifact
        uses: actions/upload-artifact@v4
        with:
          name: docker-crawler-all-tokens_export_github_stars
          path: exports/github_stars_export.csv
          retention-days: 90
      
  docker-crawler-five-tokens:
    needs: docker-crawler-all-tokens
    runs-on: "ubuntu-latest"
    
    # Set environment variables for all steps
    env:
      TOKEN: ${{ secrets.TOKEN }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Docker Build
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        run: |
          docker build -t github-stars-crawler .
          echo "Docker image built successfully"
          
      - name: Start PostgreSQL container
        run: |
          docker run -d \
            --name postgres \
            -e POSTGRES_USER=postgres \
            -e POSTGRES_PASSWORD=postgres \
            -e POSTGRES_DB=github_stars \
            -p 5432:5432 \
            postgres:14
          
          # Wait for PostgreSQL to be ready
          echo "Waiting for PostgreSQL to be ready..."
          timeout 30s bash -c 'until docker exec postgres pg_isready -U postgres; do sleep 1; done'
          echo "PostgreSQL is ready"
      
      - name: Initialize database
        run: |
          # Export TOKEN secret to environment variable
          export TOKEN="${{ secrets.TOKEN }}"
          
          # Use the separate init_database.py script
          docker run --rm \
            --network host \
            -e DB_HOST=localhost \
            -e DB_PORT=5432 \
            -e DB_USER=postgres \
            -e DB_PASSWORD=postgres \
            -e DB_NAME=github_stars \
            -e DATABASE_URL=postgresql://postgres:postgres@localhost:5432/github_stars \
            -e TOKEN \
            --entrypoint python \
            github-stars-crawler \
            init_database.py
          
          echo "Database initialized successfully"
      
      - name: Run Crawler All Tokens
        run: |
          # Export TOKEN secret to environment variable
          export TOKEN="${{ secrets.TOKEN }}"
          
          # Create directories for outputs
          mkdir -p exports logs/metrics
          
          docker run --rm \
            --network host \
            -e DB_HOST=localhost \
            -e DB_PORT=5432 \
            -e DB_USER=postgres \
            -e DB_PASSWORD=postgres \
            -e DB_NAME=github_stars \
            -e DATABASE_URL=postgresql://postgres:postgres@localhost:5432/github_stars \
            -e TOKEN \
            -v $(pwd)/exports:/app/exports \
            -v $(pwd)/logs:/app/logs \
            --entrypoint python \
            github-stars-crawler \
            crawl.py --repos 10000 --workers 16 --batch-size 10000 --clean-db --max-tokens 5
          
          echo "Crawler completed successfully"
      
      - name: Export database to CSV
        run: |
          # Export TOKEN secret to environment variable
          export TOKEN="${{ secrets.TOKEN }}"
          
          # Export the database using the Docker container
          docker run --rm \
            --network host \
            -e DB_HOST=localhost \
            -e DB_PORT=5432 \
            -e DB_USER=postgres \
            -e DB_PASSWORD=postgres \
            -e DB_NAME=github_stars \
            -e DATABASE_URL=postgresql://postgres:postgres@localhost:5432/github_stars \
            -e TOKEN \
            -v $(pwd)/exports:/app/exports \
            --entrypoint python \
            github-stars-crawler \
            export_to_csv.py --verbose
          
          # Check if export was successful
          if [ -f exports/github_stars_export.csv ]; then
            echo "Export completed successfully"
            echo "File info: $(ls -la exports/github_stars_export.csv)"
            echo "Number of rows: $(wc -l < exports/github_stars_export.csv)"
          else
            echo "Export file not found, creating minimal CSV"
            echo "id,github_id,full_name,error_message" > exports/github_stars_export.csv
            echo "0,0,export_failed,file_not_found" >> exports/github_stars_export.csv
          fi
      
      - name: Upload CSV export as artifact
        uses: actions/upload-artifact@v4
        with:
          name: docker-crawler-five-tokens_export_github_stars
          path: exports/github_stars_export.csv
          retention-days: 90
      
  docker-crawler-one-token:
    needs: docker-crawler-five-tokens
    runs-on: "ubuntu-latest"
    
    # Set environment variables for all steps
    env:
      TOKEN: ${{ secrets.TOKEN }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Docker Build
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        run: |
          docker build -t github-stars-crawler .
          echo "Docker image built successfully"
          
      - name: Start PostgreSQL container
        run: |
          docker run -d \
            --name postgres \
            -e POSTGRES_USER=postgres \
            -e POSTGRES_PASSWORD=postgres \
            -e POSTGRES_DB=github_stars \
            -p 5432:5432 \
            postgres:14
          
          # Wait for PostgreSQL to be ready
          echo "Waiting for PostgreSQL to be ready..."
          timeout 30s bash -c 'until docker exec postgres pg_isready -U postgres; do sleep 1; done'
          echo "PostgreSQL is ready"
      
      - name: Initialize database
        run: |
          # Export TOKEN secret to environment variable
          export TOKEN="${{ secrets.TOKEN }}"
          
          # Use the separate init_database.py script
          docker run --rm \
            --network host \
            -e DB_HOST=localhost \
            -e DB_PORT=5432 \
            -e DB_USER=postgres \
            -e DB_PASSWORD=postgres \
            -e DB_NAME=github_stars \
            -e DATABASE_URL=postgresql://postgres:postgres@localhost:5432/github_stars \
            -e TOKEN \
            --entrypoint python \
            github-stars-crawler \
            init_database.py
          
          echo "Database initialized successfully"
      
      - name: Run Crawler All Tokens
        run: |
          # Export TOKEN secret to environment variable
          export TOKEN="${{ secrets.TOKEN }}"
          
          # Create directories for outputs
          mkdir -p exports logs/metrics
          
          docker run --rm \
            --network host \
            -e DB_HOST=localhost \
            -e DB_PORT=5432 \
            -e DB_USER=postgres \
            -e DB_PASSWORD=postgres \
            -e DB_NAME=github_stars \
            -e DATABASE_URL=postgresql://postgres:postgres@localhost:5432/github_stars \
            -e TOKEN \
            -v $(pwd)/exports:/app/exports \
            -v $(pwd)/logs:/app/logs \
            --entrypoint python \
            github-stars-crawler \
            crawl.py --repos 10000 --workers 16 --batch-size 10000 --clean-db --max-tokens 1
          
          echo "Crawler completed successfully"
      
      - name: Export database to CSV
        run: |
          # Export TOKEN secret to environment variable
          export TOKEN="${{ secrets.TOKEN }}"
          
          # Export the database using the Docker container
          docker run --rm \
            --network host \
            -e DB_HOST=localhost \
            -e DB_PORT=5432 \
            -e DB_USER=postgres \
            -e DB_PASSWORD=postgres \
            -e DB_NAME=github_stars \
            -e DATABASE_URL=postgresql://postgres:postgres@localhost:5432/github_stars \
            -e TOKEN \
            -v $(pwd)/exports:/app/exports \
            --entrypoint python \
            github-stars-crawler \
            export_to_csv.py --verbose
          
          # Check if export was successful
          if [ -f exports/github_stars_export.csv ]; then
            echo "Export completed successfully"
            echo "File info: $(ls -la exports/github_stars_export.csv)"
            echo "Number of rows: $(wc -l < exports/github_stars_export.csv)"
          else
            echo "Export file not found, creating minimal CSV"
            echo "id,github_id,full_name,error_message" > exports/github_stars_export.csv
            echo "0,0,export_failed,file_not_found" >> exports/github_stars_export.csv
          fi
      
      - name: Upload CSV export as artifact
        uses: actions/upload-artifact@v4
        with:
          name: docker-crawler-one-token_export_github_stars
          path: exports/github_stars_export.csv
          retention-days: 90
      
  # Optional - create a Docker image and push to registry
  build-and-push:
    needs: docker-crawler-all-tokens
    runs-on: "ubuntu-latest"
    if: github.ref == 'refs/heads/main'  # Only run on main branch
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ghcr.io/${{ github.repository_owner }}/github-stars-crawler:latest
            ghcr.io/${{ github.repository_owner }}/github-stars-crawler:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max